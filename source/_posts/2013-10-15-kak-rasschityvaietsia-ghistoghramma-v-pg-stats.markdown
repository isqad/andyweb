---
layout: post
title: "Как рассчитывается гистограмма в pg_stats"
date: 2013-10-15 19:21
comments: true
categories:
---
Для чтения этого поста вы должны быть знакомы с представлением pg_stats и зачем нужна сборка статистики в Postgresql.
В данном посте я попытаюсь раскрыть механизм рассчета поля histogram_bounds в представлении pg_stats. Весь исходный код
находится в открытом доступе, я использовал форк postgresql на [gihub](https://github.com/postgres/postgres/blob/master/src/backend/commands/analyze.c).

Открываем analyze.c и переходим к строчке [#1780](https://github.com/postgres/postgres/blob/master/src/backend/commands/analyze.c#L1780). Здесь все и начинается.

Несколько пояснений:

* Нам для рассчета гистограммы нужна минимальная случайная выборка из строк таблицы (из которой собираем статистику), stats->minrows;
* attr->attstattarget - та самая настройка максимальной длины списков most_common_values и histogram_bounds;
* расчет минимальной статистики для типов данных нескаляров происходит в функции compute_minimal_stats;
* для скаляров же - compute_scalar_stats.

1. Определяем тип значений столбца. Если это скаляр (проверка на ltopr прошла), выбираем стандартный алгоритм. На нужно
определить minrows - минимальное число строк для построения статистики. minrows определяется на основании теоремы 5 из
статьи ["Random sampling for histogram construction: how much is enough?"](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.53.1734&rep=rep1&type=pdf). Теорема гласит, что для таблицы размером n, гистограммы размером k, минимальной относительной погрешности f, и вероятностной погрешности gamma, размер минимальной случайно выборки будет следующим:

```
r = 4*k*ln(2*n/gamma)/f^2
```

Принимая f = 0.5, gamma = 0.01, n = 10^6 строк, мы получим:

```
r = 308.82*k
```

Так как это логарифмическая функция, зависимость результата от n низкая; даже при n = 10^12, у нас выйдет:

```
r = 300*k
```

Соответственно, минимальный размер для случайной выборки рассчитывается так:

```
minrows = 300*attstattarget
```

2. Для типа столбца, для которого мы не можем применить оператор "=", мы рассчитываем только минимальную статистику: долю не NULL значений, среднюю ширину, most_common_values, и оценочное количество уникальных значений в столбце. Рассчет ее происходит в compute_minimal_stats.

3. Когда для типа столбца мы нашли такие операторы как "=" и "<", то можем рассчитать кроме всего прочего еще и гистограмму и коррелляцию физ. и логического порядка в столбце.

4. Гистограммы генерируется если по меньшей мере 2 уникальных значения не учитывались в mcv (most_common_values) списке: num_hist = ndistinct - num_mcv

5. Формируем список из дупликатов в столбце: сохраняем в каждом элементе списке количество дупликатов конкретного значения и "индекс" его первого появления (то есть здесь мы сохраняем какбы информацию, о том когда впервые встретилось значение)

6. Сортируем mcv значения (quick sort) в положеном порядке для ускорения цикла

7. После сортировки мы делаем свертку из mcv значений. Получаем nvals - количество оставшихся после свертки значений в списке

8. Считаем:

```
delta = (nvals-1)/(num_hist-1)
deltafrac = (nvals-1)%(num_hist-1)
pos=posfrac=0
```

В цикле копируем первые и последние значения из свернутого списка вместе с равномерно расположенными значениями между ними. Так i-ое значение это i*delta. Но такой рассчет напрямую проводить нельзя, поэтому, на каждой итерации к предыдущей позиции прибавляем delta для того, чтобы получить следующее значение для гистограммы, и следим за целой и дробной частью суммы раздельно. Все это сделано просто для того, чтобы не при умножении i на delta предостеречься от переполнения :)

```
for (i = 0; i < num_hist; i++) {
  hist_vals[i] = values[pos].value;
  pos += delta;
  posfrac += deltafrac;
  // дробная часть > 1 - приводим к целой части
  if (posfrac >= (num_hist-1)) {
    pos++;
    posfrac -= (num_hist - 1);
  }
}
```

Вот мы и получили hist_vals - массив значений для гистограммы.

